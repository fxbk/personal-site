(this["webpackJsonppersonal-site"]=this["webpackJsonppersonal-site"]||[]).push([[13],{167:function(e,t,n){"use strict";n.r(t);var a=n(0),i=(n(53),n(1),n(5),n(62),n(21)),s="/personal-site";t.default=function(){return Object(a.jsx)(i.a,{description:"Felix Bok's personal",children:Object(a.jsxs)("article",{className:"post",id:"index",children:[Object(a.jsx)("header",{children:Object(a.jsxs)("div",{className:"title",children:[Object(a.jsx)("h2",{"data-testid":"heading",children:"OpenAI Gym: Q-Learning"}),Object(a.jsxs)("p",{children:[" Solving the ",Object(a.jsx)("a",{href:"",children:"OpenAI Gym "}),' environments "Taxi" and "Frozen Lake" with Q-Learning ']}),Object(a.jsx)("img",{className:"image",src:"".concat(s,"/images/projects/q-learning.jpg"),alt:"robo child"})]})}),Object(a.jsx)("p",{children:"OpenAI Gym provides different environments and corresponding problems that can be solved using reinforcement learning (RL) techniques. Since I am absolutely fascinated by RL approach, where an agent tries to optimize its reward by random actions and learns which action at which state returns the maximum reward, I started to learn and experiment with RL and OpenAI gym."}),Object(a.jsxs)("p",{children:["With the help of Q-Learning, the easiest methods of RL, I was able to solve the",Object(a.jsx)("a",{href:"https://gym.openai.com/envs/Taxi-v3/",children:" Taxi "}),", as well as the",Object(a.jsx)("a",{href:"https://gym.openai.com/envs/FrozenLake-v0/",children:" Frozen Lake"})," environment."]}),Object(a.jsxs)("p",{children:["The repo is linked ",Object(a.jsx)("a",{href:"https://github.com/fxbk/Q_learning",children:"here"}),"."]}),Object(a.jsxs)("figure",{role:"group",children:[Object(a.jsx)("figcaption",{children:"Examples of a trained agent on the taxi and frozen lake environment can be seen below."}),Object(a.jsxs)("figure",{children:[Object(a.jsx)("img",{className:"image",src:"".concat(s,"/images/projects/taxi.gif"),alt:"taxi"}),Object(a.jsx)("figcaption",{children:"Taxi example, the goal is to pick up a passenger at Y and drop them of at G"})]}),Object(a.jsxs)("figure",{children:[Object(a.jsx)("img",{className:"image",src:"".concat(s,"/images/projects/frozen-lake.gif"),alt:"fozen-lake",height:"230"}),Object(a.jsx)("figcaption",{children:"Frozen Lake example, the goal is to get from S to G only using the F fields. The H stands for holes where the agent should walk by (most of the time xD)."})]})]})]})})}}}]);
//# sourceMappingURL=13.1708df35.chunk.js.map