{"version":3,"sources":["pages/projects/deep-q.js"],"names":["deep_q","description","className","id","data-testid","href","src","process","alt","width"],"mappings":"yKAsDeA,UA5CA,kBACb,cAAC,IAAD,CACEC,YAAa,uBADf,SAGE,0BAASC,UAAU,OAAOC,GAAG,QAA7B,UACE,iCACE,sBAAKD,UAAU,QAAf,UACE,oBAAIE,cAAY,UAAhB,yCACE,wDAA0B,mBAAGC,KAAK,GAAR,yBAA1B,2DACA,qBAAKH,UAAU,QAAQI,IAAG,UAbfC,GAae,wCAAuDC,IAAI,oBAG3F,mqBAQA,+bAMA,uIAGA,qBAAKN,UAAU,QAAQI,IAAG,UAjCTC,GAiCS,oCAAmDC,IAAI,kBAAkBC,MAAM,QACzG,ibAMA,oDACqB,mBAAGJ,KAAM,gCAAT,kBADrB","file":"static/js/14.35fe38a6.chunk.js","sourcesContent":["import React from 'react';\nimport { Link } from 'react-router-dom';\nimport ReactMarkdown from 'react-markdown';\nimport raw from 'raw.macro';\n\nimport Main from '../../layouts/Main';\nconst { PUBLIC_URL } = process.env; // set automatically from package.json:homepage\n\nconst LinkRenderer = ({ ...children }) => <Link {...children} />;\n\nconst deep_q = () => (\n  <Main\n    description={\"Felix Bok's personal\"}\n  >\n    <article className=\"post\" id=\"index\">\n      <header>\n        <div className=\"title\">\n          <h2 data-testid=\"heading\">OpenAI Gym: Deep Q-Learning</h2>\n            <p> Trying to solving the <a href=\"\" >OpenAI Gym </a> environments \"MountainClimber\" with deep Q-Learning </p>\n            <img className=\"image\" src={`${PUBLIC_URL}/images/projects/deep-q-learning.jpg`} alt='robo peace'/>\n        </div>\n      </header>\n      <p>\n          After solving the Taxi and Frozen Lake environment with basic Q-Learning I tried to solve more advanced reinforcement\n          learning (RL) problems. One of the most classical examples of RL in general is the mountain climber problem, where\n          a car, placed between two hills, has to drive up the bigger hill with the catch, that the car is not strong enough\n          to directly reach the finish line. Instead, it first has to build up momentum by driving forward and backward. This brings\n          multiple challenges with it. First the states of the environment is now much larger as with previous environments,\n          and second the agent has to remember what it did before.\n      </p>\n      <p>\n          In order to solve this problem I used deep Q-Learning. The main idea of deep Q-Learning is to use\n          a deep neural network (dnn) to model a function that maps the current state and the a part of the history of\n          states onto the action space. This has the benefit over classical Q-Learning, that not all different states combinations\n          has to be stored in a large matrix, that for more advanced problems can be unfeasible.\n      </p>\n      <p>\n          After implementing the necessary code and fine tuning a rather smaller dnn I got the following result:\n      </p>\n      <img className=\"image\" src={`${PUBLIC_URL}/images/projects/mountaincar.gif`} alt=\"mountainclimber\" width=\"50%\"/>\n      <p>\n          As you can see, the agent learned that it has to get momentum in order to get up the right hill, but then decides\n          to break and return back to the left hill again &#x1F648;. It seems that the agent does not know its velocity or has\n          a too short memory to know that it already gained momentum. I would love to continue working on this problem, but due\n          to time constrains I could not finally solve it.\n      </p>\n      <p>\n        The repo is linked <a href={\"https://github.com/fxbk/deepQ\"}>here</a>.\n      </p>\n    </article>\n\n  </Main>\n);\n\nexport default deep_q;"],"sourceRoot":""}