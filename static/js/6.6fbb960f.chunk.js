(this["webpackJsonppersonal-site"]=this["webpackJsonppersonal-site"]||[]).push([[6],{170:function(e,t,n){"use strict";n.r(t);var i=n(0),r=(n(49),n(1),n(5),n(21));t.default=function(){return Object(i.jsx)(r.a,{description:"Felix Bok's personal",children:Object(i.jsxs)("article",{className:"post",id:"index",children:[Object(i.jsx)("header",{children:Object(i.jsxs)("div",{className:"title",children:[Object(i.jsx)("h2",{"data-testid":"heading",children:"Lux AI Kaggle Challenge"}),Object(i.jsxs)("p",{children:[" Competing in the ",Object(i.jsx)("a",{href:"https://www.kaggle.com/c/lux-ai-2021",children:"Lux AI Kaggle Challenge "})," to apply RL methods "]}),Object(i.jsx)("img",{className:"image",src:"".concat("/personal-site","/images/projects/lux-challenge.png"),alt:"lux challenge banner"})]})}),Object(i.jsxs)("p",{children:["Together with ",Object(i.jsx)("a",{href:"https://www.linkedin.com/in/erik-steiger/",children:" Erik Steiger "}),', a good friend and fellow student of mine, we competed on the Kaggle Challenge "Lux AI 2021". The goal of the challenge was to train agents with reinforcement learning methods to enable them to survive in a given environment and doing it better than an opponent. The environment is basically a board game where two players compete about limited resources, building cities and fight against the upcoming dark night.']}),Object(i.jsxs)("p",{children:["Our idea was to use a Graph Neural Network (GNN) and the ",Object(i.jsx)("a",{href:"https://arxiv.org/abs/1707.06347",children:"Proximal Policy Optimization (PPO) algorithm"}),". The idea was based on the paper",Object(i.jsx)("a",{href:"https://arxiv.org/pdf/2107.08387.pdf",children:" TRAIN ON SMALL, PLAY THE LARGE: SCALING UP BOARD GAMES WITH ALPHAZERO AND GNN"}),", where each node in the GNN represents one position on a board game. As the authors showed, the benefit of using GNN is the possibility of training the node neural network first on a small board game, learning first basic strategies, and then to scale up the board and let the agent learn more complex strategies."]}),Object(i.jsxs)("p",{children:["We implemented our approach, using PyTorch and RLlib. The repository can be found",Object(i.jsx)("a",{href:"https://github.com/cerebro-ai/lux-ai-2021",children:" here"}),"."]}),Object(i.jsx)("p",{children:"Unfortunately, we fell into a really common RL fallacy. A most common problem with RL is that the code mostly fails silently, meaning that the code is running but the agent does not learn something. Additional, depending on the complexity of the environment, RL takes quite some computational time to start learning something. Therefore, it is recommended to test the code on simpler RL problems, f.e. one provided by OpenAI gym and to do a lot of experiments while stepwise increasing the complexity of the algorithm. Unfortunately, we have to learn this the hard way... while we did some tests in the beginning of the project, we at some point were too focused on our idea, that we missed out on testing our idea. And when we noticed that the challenge was almost over."}),Object(i.jsx)("p",{children:"In summary, we really enjoyed working on our first Kaggle challenge and we learned quite a lot. This will definitely not be our only programming project that we will do."})]})})}},49:function(e,t,n){"use strict";n.d(t,"a",(function(){return o}));var i=n(51);function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){Object(i.a)(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}},51:function(e,t,n){"use strict";function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}n.d(t,"a",(function(){return i}))}}]);
//# sourceMappingURL=6.6fbb960f.chunk.js.map