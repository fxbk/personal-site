(this["webpackJsonppersonal-site"]=this["webpackJsonppersonal-site"]||[]).push([[14],{169:function(e,t,n){"use strict";n.r(t);var i=n(0),a=(n(49),n(1),n(5),n(57),n(21));t.default=function(){return Object(i.jsx)(a.a,{description:"Felix Bok's personal",children:Object(i.jsxs)("article",{className:"post",id:"index",children:[Object(i.jsx)("header",{children:Object(i.jsxs)("div",{className:"title",children:[Object(i.jsx)("h2",{"data-testid":"heading",children:"OpenAI Gym: Deep Q-Learning"}),Object(i.jsxs)("p",{children:[" Trying to solving the ",Object(i.jsx)("a",{href:"",children:"OpenAI Gym "}),' environments "MountainClimber" with deep Q-Learning ']}),Object(i.jsx)("img",{className:"image",src:"".concat("","/images/projects/deep-q-learning.jpg"),alt:"robo peace"})]})}),Object(i.jsx)("p",{children:"After solving the Taxi and Frozen Lake environment with basic Q-Learning I tried to solve more advanced reinforcement learning (RL) problems. One of the most classical examples of RL in general is the mountain climber problem, where a car, placed between two hills, has to drive up the bigger hill with the catch, that the car is not strong enough to directly reach the finish line. Instead, it first has to build up momentum by driving forward and backward. This brings multiple challenges with it. First the states of the environment is now much larger as with previous environments, and second the agent has to remember what it did before."}),Object(i.jsx)("p",{children:"In order to solve this problem I used deep Q-Learning. The main idea of deep Q-Learning is to use a deep neural network (dnn) to model a function that maps the current state and the a part of the history of states onto the action space. This has the benefit over classical Q-Learning, that not all different states combinations has to be stored in a large matrix, that for more advanced problems can be unfeasible."}),Object(i.jsx)("p",{children:"After implementing the necessary code and fine tuning a rather smaller dnn I got the following result:"}),Object(i.jsx)("img",{className:"image",src:"".concat("","/images/projects/mountaincar.gif"),alt:"mountainclimber",width:"50%"}),Object(i.jsx)("p",{children:"As you can see, the agent learned that it has to get momentum in order to get up the right hill, but then decides to break and return back to the left hill again \ud83d\ude48. It seems that the agent does not know its velocity or has a too short memory to know that it already gained momentum. I would love to continue working on this problem, but due to time constrains I could not finally solve it."}),Object(i.jsxs)("p",{children:["The repo is linked ",Object(i.jsx)("a",{href:"https://github.com/fxbk/deepQ",children:"here"}),"."]})]})})}}}]);
//# sourceMappingURL=14.35fe38a6.chunk.js.map